{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMY2PpUBPfQIkXiOiViGjJS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/LLM-Utility-Cookbook/blob/main/VoiceToText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voice to Text Transcription with the OpenAI Whisper API\n",
        "This Jupyter notebook demonstrates a Voice-to-Text transcription system using OpenAI's API. \n",
        "\n",
        "## Installation of Necessary Libraries 🔧\n",
        "\n",
        "The notebook starts by installing the necessary libraries - \n",
        "`ipywebrtc` is used to handle the audio stream from the user's microphone, `pydub` is used for audio processing, and `openai` is for leveraging OpenAI's APIs for transcription."
      ],
      "metadata": {
        "id": "CRsTklRyCEnI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G8Sqv-59HYl"
      },
      "outputs": [],
      "source": [
        "!pip install ipywebrtc\n",
        "!pip install pydub\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fmpeg is a free and open-source software suite used for handling multimedia data. In this case, it's used to convert the audio file to the correct format for transcription."
      ],
      "metadata": {
        "id": "hHONws76CdX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install ffmpeg"
      ],
      "metadata": {
        "id": "5iafBC42_D9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "lBoIzsDs_ui5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to set your OpenAI API key. The key is used to authenticate your requests to the OpenAI API."
      ],
      "metadata": {
        "id": "Lq9awY5zChyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = '' # <- Your openAI API key"
      ],
      "metadata": {
        "id": "cTR8Bk4e_xX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section enables the use of custom widgets in Google Colab. in our case a Audio recorder"
      ],
      "metadata": {
        "id": "ue3gVxWyCkTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "yNIGixu_9bH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recording the Audio 🎙️"
      ],
      "metadata": {
        "id": "w5nSnvjSCzh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywebrtc import CameraStream, AudioRecorder, WidgetStream\n",
        "\n",
        "# Create an audio stream. Set 'constraints' to get audio without video.\n",
        "audio_stream = CameraStream(constraints=\n",
        "                            {'audio': True, \n",
        "                             'video': False})\n",
        "\n",
        "# Create an audio recorder that uses the audio stream\n",
        "recorder = AudioRecorder(stream=audio_stream)\n",
        "\n",
        "# Hit the \"Record\" button to start recording\n",
        "# \"Recording... \" will be displayed while recording\n",
        "recorder\n"
      ],
      "metadata": {
        "id": "DVN4QgiB-Ppz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the recording as a .webm file\n",
        "recorder.save('recording.webm')"
      ],
      "metadata": {
        "id": "ZHkJR1J4-Tja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have the audio recording, it's converted from the .webm format to .mp3 format using ffmpeg."
      ],
      "metadata": {
        "id": "fKVOoDC5C90e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i recording.webm -vn -ab 128k -ar 44100 -y recording.mp3"
      ],
      "metadata": {
        "id": "U0x5BYJx_HGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcribing the Audio 📝\n",
        "Finally, the .mp3 file is transcribed into text using OpenAI's transcription service."
      ],
      "metadata": {
        "id": "wpOWH9IjDFEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file= open(\"recording.mp3\", \"rb\")\n",
        "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)"
      ],
      "metadata": {
        "id": "MNuT2KFb_7St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictTranscript = transcript.to_dict()"
      ],
      "metadata": {
        "id": "MftPwCKcADcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictTranscript"
      ],
      "metadata": {
        "id": "RE89Gi1oAFI7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}